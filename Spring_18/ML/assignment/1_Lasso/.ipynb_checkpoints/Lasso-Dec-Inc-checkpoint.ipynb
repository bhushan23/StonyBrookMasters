{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fDF = pd.read_csv('Data/featureTypes.txt', names=['featureID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 1)\n",
      "flavors raspberries cherries\n"
     ]
    }
   ],
   "source": [
    "print fDF.shape\n",
    "print fDF['featureID'][0]\n",
    "n = 10000\n",
    "d = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247847\n"
     ]
    }
   ],
   "source": [
    "trainDF = pd.read_csv('Data/trainData.txt', names = ['instanceID', 'featureID', 'value'], sep=' ')\n",
    "YDF = pd.read_csv('Data/trainLabels.txt', names = ['label'])\n",
    "valXDF = pd.read_csv('Data/valData.txt', names = ['instanceID', 'featureID', 'value'], sep=' ')\n",
    "valYDF = pd.read_csv('Data/valLabels.txt', names = ['label'])\n",
    "print trainDF.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000,)\n"
     ]
    }
   ],
   "source": [
    "W = np.random.uniform(low=0.0, high=1.0,size = (d,))\n",
    "B = np.zeros(n)\n",
    "print W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instanceID</th>\n",
       "      <th>featureID</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>0.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>228</td>\n",
       "      <td>0.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>242</td>\n",
       "      <td>0.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>371</td>\n",
       "      <td>0.209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instanceID  featureID  value\n",
       "0           1         13  0.209\n",
       "1           1         83  0.209\n",
       "2           1        228  0.209\n",
       "3           1        242  0.209\n",
       "4           1        371  0.209"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tDF = csr_matrix(trainDF) \n",
    "#print tDF[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sdf = pd.SparseDataFrame(tDF)\n",
    "#print sdf[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will lead to negative index if re-running\n",
    "trainDF['instanceID'] -= 1\n",
    "trainDF['featureID'] -= 1\n",
    "sMat = csr_matrix((trainDF['value'], (trainDF['featureID'], trainDF['instanceID'])))\n",
    "valXDF['instanceID'] -= 1\n",
    "valXDF['featureID'] -= 1\n",
    "valX = csr_matrix((valXDF['value'], (valXDF['featureID'], valXDF['instanceID'])))\n",
    "Y = YDF['label'].as_matrix().transpose()\n",
    "#print Y.shape\n",
    "valY = valYDF['label'].as_matrix().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print sMat.shape\n",
    "#print sMat.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print sMat[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 10000)\n"
     ]
    }
   ],
   "source": [
    "X = sMat.copy()\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "896.6381332\n"
     ]
    }
   ],
   "source": [
    "def initLamda(X, Y):\n",
    "    YNorm = Y - float(Y.sum())/((float)(Y.shape[0]))\n",
    "    return 2 * ((X * YNorm).max())\n",
    "    \n",
    "print initLamda(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tX = X.copy()\n",
    "#print tX\n",
    "#tX.data **= 2\n",
    "#tA = 2*tX.sum(axis = 1)\n",
    "#print max(tA), min(tA)\n",
    "#print tA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = X.copy()\n",
    "#print t[0]\n",
    "#print t[0].sum()\n",
    "#t.data **= 2\n",
    "#print t[0].sum()\n",
    "#print t\n",
    "#TA = 2*t.sum(axis = 1)\n",
    "#print TA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this to convergence condition\n",
    "\n",
    "def rmse(input1, input2):\n",
    "    out = input1 - input2\n",
    "    #print out\n",
    "    out **= 2\n",
    "    out /= len(out)\n",
    "    error = out.sum()\n",
    "    return math.sqrt(error)\n",
    "\n",
    "\n",
    "class Lasso:\n",
    "    def __init__(self, X, Y, W, B, Lamda):\n",
    "        self.X = X.copy()\n",
    "        self.Y = Y.copy()\n",
    "        self.W = W #.copy()  # Remove this copy later\n",
    "        self.B = B #.copy()\n",
    "        t = X.copy()\n",
    "        t.data **= 2\n",
    "        self.A = 2*t.sum(axis = 1)\n",
    "        self.Lamda = Lamda\n",
    "        self.delta = 0.01\n",
    "        # Stores Lamda and respective RMSE\n",
    "        self.trainrmse = []\n",
    "        self.trainlamda = []\n",
    "        self.valrmse = []\n",
    "        self.vallamda = []\n",
    "        self.NonZero = []\n",
    "        \n",
    "    def loss(self):\n",
    "        return ((self.X.transpose() * self.W + self.B - self.Y) ** 2).sum() + self.Lamda * (abs(self.W)).sum()\n",
    "        \n",
    "    def fit(self):\n",
    "        # Lamda = initLamda(self.X, self.Y)\n",
    "        \n",
    "        #print X.shape, W.shape\n",
    "        #for epoch in range(100):\n",
    "        oldLoss = self.loss()+2\n",
    "        newLoss = self.loss()\n",
    "        print 'Lamda: ', self.Lamda\n",
    "        while oldLoss - newLoss > self.delta:\n",
    "            #print sMat.transpose() * W\n",
    "            # 4.1.1\n",
    "            #print t1[:5], t1.shape\n",
    "            #print t1.shape, B.shape, Y.shape\n",
    "            XTW = (self.X.transpose() * self.W)\n",
    "            R = self.Y - (self.X.transpose() * self.W) - self.B\n",
    "             \n",
    "            # 4.1.2\n",
    "            self.B = (R + self.B) / n \n",
    "            #self.B = (self.Y - XTW) / n\n",
    "            #print B.shape\n",
    "            # 4.1.3\n",
    "            R = (n-1) * self.B\n",
    "            #R = self.Y - (XTW + self.B)\n",
    "            #print R.shape\n",
    "            #print R[:5]\n",
    "            # R = R.reshape(-1)\n",
    "            for ik in range(0, d):\n",
    "                # 4.1.4\n",
    "                #ik = 0\n",
    "                t = (self.X[ik].transpose() * self.W[ik]).toarray().reshape(-1)\n",
    "                #print t\n",
    "                #print t.shape\n",
    "                #print R.shape\n",
    "                Ck = (2 * self.X[ik] * (R + t)).sum()\n",
    "                #Ck = (2 * self.X[ik] * (self.Y - self.B - t)).sum()\n",
    "                #print Ck.sum()\n",
    "                # Update Weight\n",
    "                WkOld = self.W[ik]\n",
    "                if Ck < -self.Lamda:\n",
    "                    self.W[ik] = (Ck + self.Lamda) / self.A[ik]\n",
    "                elif Ck > self.Lamda:\n",
    "                    self.W[ik] = (Ck - self.Lamda) / self.A[ik]\n",
    "                else:\n",
    "                    self.W[ik] = 0\n",
    "                #print W[ik]\n",
    "                # 4.1.5\n",
    "                # print self.W[ik], WkOld\n",
    "                #print X[ik].toarray().reshape(-1).shape, R.shape\n",
    "                R = R + self.X[ik].toarray().reshape(-1) * (WkOld - self.W[ik])\n",
    "                #R = self.Y - (self.X.transpose() * self.W) + self.B\n",
    "            oldLoss = newLoss\n",
    "            newLoss = model.loss()\n",
    "            #print oldLoss, newLoss, oldLoss - newLoss\n",
    "            print 'LOSS:' , newLoss\n",
    "            # End of feature vector iterator\n",
    "    \n",
    "    def saveModel(self, filename):\n",
    "        pickle.dump(self, open( filename, \"wb\" ))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return (X.transpose() * self.W + self.B)\n",
    "    \n",
    "    def chooseCorrectLamda(self, delta = -1):\n",
    "        oldLamda = self.Lamda\n",
    "        if delta != -1:\n",
    "            self.delta = delta\n",
    "        self.fit()\n",
    "        \n",
    "        newRMSE = rmse(self.predict(self.X), self.Y)\n",
    "        #self.TrainInfo.append([self.Lamda, newRMSE])\n",
    "        self.trainrmse.append(newRMSE)\n",
    "        self.trainlamda.append(self.Lamda)\n",
    "        valRMSE = rmse(self.predict(valX), valY)\n",
    "        self.valrmse.append(valRMSE)\n",
    "        self.vallamda.append(self.Lamda)\n",
    "        oldRMSE = valRMSE\n",
    "        #print W\n",
    "        #self.ValInfo.append([self.Lamda, valRMSE])\n",
    "        self.NonZero.append((self.W != 0).sum())\n",
    "        print 'Lamda: ', self.Lamda, 'RMSE: ', newRMSE, 'Val RMSE:' , valRMSE\n",
    "        \n",
    "        while oldRMSE >= valRMSE:\n",
    "            oldLamda = self.Lamda\n",
    "            self.Lamda /= 2\n",
    "            self.fit()\n",
    "            oldRMSE = valRMSE\n",
    "            #self.TrainInfo.append([self.Lamda, newRMSE])\n",
    "            newRMSE = rmse(self.predict(self.X), self.Y)\n",
    "            self.trainrmse.append(newRMSE)\n",
    "            self.trainlamda.append(self.Lamda)\n",
    "            valRMSE = rmse(self.predict(valX), valY)\n",
    "            #self.ValInfo.append([self.Lamda, valRMSE])\n",
    "            self.valrmse.append(valRMSE)\n",
    "            self.vallamda.append(self.Lamda)\n",
    "            self.NonZero.append((self.W != 0).sum())\n",
    "            #self.NonZero.append(self.W.toarray().count_nonzero())\n",
    "            print 'Lamda: ', self.Lamda, 'RMSE: ', newRMSE, 'Val RMSE:' , valRMSE\n",
    "            self.saveModel('optimal_saved_Model')\n",
    "            \n",
    "        self.Lamda = oldLamda\n",
    "        self.fit()\n",
    "        return oldLamda\n",
    "    \n",
    "def loadModel(filename):\n",
    "    return pickle.load(open(filename, \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lasso(X, Y, W, B, initLamda(X.copy(), Y.copy()))\n",
    "#model.loss()\n",
    "#model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "896.6381332\n"
     ]
    }
   ],
   "source": [
    "print model.Lamda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lamda:  896.6381332\n",
      "LOSS: 34336469.1313\n",
      "LOSS: 18466334.6274\n",
      "LOSS: 13768837.7702\n",
      "LOSS: 11354012.7077\n",
      "LOSS: 9915299.48747\n",
      "LOSS: 9014223.85761\n",
      "LOSS: 8479527.54943\n",
      "LOSS: 8156629.74387\n",
      "LOSS: 7928391.50063\n",
      "LOSS: 7737816.78555\n",
      "LOSS: 7570608.30543\n",
      "LOSS: 7440472.84433\n",
      "LOSS: 7348011.65908\n",
      "LOSS: 7284000.31816\n",
      "LOSS: 7235019.25523\n",
      "LOSS: 7196139.3727\n",
      "LOSS: 7164490.47345\n",
      "LOSS: 7139518.86226\n",
      "LOSS: 7120239.1819\n",
      "LOSS: 7105326.79451\n",
      "LOSS: 7093643.43495\n",
      "LOSS: 7084224.68983\n",
      "LOSS: 7076703.13575\n",
      "LOSS: 7070892.33782\n",
      "LOSS: 7066486.7189\n",
      "LOSS: 7063123.76662\n",
      "LOSS: 7060463.22605\n",
      "LOSS: 7058262.21877\n",
      "LOSS: 7056454.86624\n",
      "LOSS: 7054999.8036\n",
      "LOSS: 7053852.25728\n",
      "LOSS: 7052963.48118\n",
      "LOSS: 7052279.1177\n",
      "LOSS: 7051752.80011\n",
      "LOSS: 7051341.07769\n",
      "LOSS: 7051013.85735\n",
      "LOSS: 7050749.88051\n",
      "LOSS: 7050535.57106\n",
      "LOSS: 7050362.68179\n",
      "LOSS: 7050225.265\n",
      "LOSS: 7050118.37748\n",
      "LOSS: 7050036.77758\n",
      "LOSS: 7049974.38598\n",
      "LOSS: 7049926.02406\n",
      "LOSS: 7049887.72176\n",
      "LOSS: 7049856.76389\n",
      "LOSS: 7049831.55162\n",
      "LOSS: 7049811.18744\n",
      "LOSS: 7049795.03381\n",
      "LOSS: 7049782.4609\n",
      "LOSS: 7049772.83873\n",
      "LOSS: 7049765.45043\n",
      "LOSS: 7049759.69644\n",
      "LOSS: 7049755.12732\n",
      "LOSS: 7049751.44192\n",
      "LOSS: 7049748.45588\n",
      "LOSS: 7049746.05643\n",
      "LOSS: 7049744.16068\n",
      "LOSS: 7049742.68964\n",
      "LOSS: 7049741.56048\n",
      "LOSS: 7049740.69185\n",
      "LOSS: 7049740.01331\n",
      "LOSS: 7049739.47194\n",
      "LOSS: 7049739.03316\n",
      "LOSS: 7049738.67666\n",
      "LOSS: 7049738.39028\n",
      "LOSS: 7049738.16478\n",
      "LOSS: 7049737.9908\n",
      "LOSS: 7049737.85827\n",
      "LOSS: 7049737.75724\n",
      "LOSS: 7049737.67912\n",
      "LOSS: 7049737.61742\n",
      "LOSS: 7049737.56786\n",
      "LOSS: 7049737.52785\n",
      "LOSS: 7049737.49579\n",
      "LOSS: 7049737.47047\n",
      "LOSS: 7049737.45072\n",
      "LOSS: 7049737.43537\n",
      "LOSS: 7049737.42331\n",
      "LOSS: 7049737.41366\n",
      "Lamda:  896.6381332 RMSE:  18.3279559881 Val RMSE: 18.5776230253\n",
      "Lamda:  448.3190666\n",
      "LOSS: 4946096.44551\n",
      "LOSS: 4915275.30217\n",
      "LOSS: 4906921.55552\n",
      "LOSS: 4902865.50773\n",
      "LOSS: 4900491.83628\n",
      "LOSS: 4898949.48297\n",
      "LOSS: 4897893.62621\n",
      "LOSS: 4897178.80705\n",
      "LOSS: 4896701.10135\n",
      "LOSS: 4896362.06461\n",
      "LOSS: 4896090.43641\n",
      "LOSS: 4895853.02105\n",
      "LOSS: 4895655.38815\n",
      "LOSS: 4895499.91398\n",
      "LOSS: 4895380.52822\n",
      "LOSS: 4895290.78845\n",
      "LOSS: 4895221.36979\n",
      "LOSS: 4895164.38094\n",
      "LOSS: 4895115.12308\n",
      "LOSS: 4895071.89007\n",
      "LOSS: 4895034.58691\n",
      "LOSS: 4895003.52004\n",
      "LOSS: 4894978.41224\n",
      "LOSS: 4894958.49528\n",
      "LOSS: 4894942.74101\n",
      "LOSS: 4894930.1236\n",
      "LOSS: 4894919.79215\n",
      "LOSS: 4894911.10356\n",
      "LOSS: 4894903.66085\n",
      "LOSS: 4894897.26382\n",
      "LOSS: 4894891.78769\n",
      "LOSS: 4894887.1812\n",
      "LOSS: 4894883.40003\n",
      "LOSS: 4894880.36024\n",
      "LOSS: 4894877.94126\n",
      "LOSS: 4894876.00675\n",
      "LOSS: 4894874.42854\n",
      "LOSS: 4894873.103\n",
      "LOSS: 4894871.96814\n",
      "LOSS: 4894870.98899\n",
      "LOSS: 4894870.15065\n",
      "LOSS: 4894869.44649\n",
      "LOSS: 4894868.86893\n",
      "LOSS: 4894868.40496\n",
      "LOSS: 4894868.03642\n",
      "LOSS: 4894867.74264\n",
      "LOSS: 4894867.50353\n",
      "LOSS: 4894867.30277\n",
      "LOSS: 4894867.12985\n",
      "LOSS: 4894866.97925\n",
      "LOSS: 4894866.84885\n",
      "LOSS: 4894866.73806\n",
      "LOSS: 4894866.64625\n",
      "LOSS: 4894866.57193\n",
      "LOSS: 4894866.51269\n",
      "LOSS: 4894866.46555\n",
      "LOSS: 4894866.42757\n",
      "LOSS: 4894866.39628\n",
      "LOSS: 4894866.36995\n",
      "LOSS: 4894866.34754\n",
      "LOSS: 4894866.32853\n",
      "LOSS: 4894866.31266\n",
      "LOSS: 4894866.29971\n",
      "LOSS: 4894866.28934\n",
      "LOSS: 4894866.28113\n",
      "Lamda:  448.3190666 RMSE:  18.3279559881 Val RMSE: 15.6926180966\n",
      "Lamda:  224.1595333\n",
      "LOSS: 3466147.10893\n",
      "LOSS: 3449002.36952\n",
      "LOSS: 3444854.20316\n",
      "LOSS: 3442950.04061\n",
      "LOSS: 3441787.52318\n",
      "LOSS: 3440934.90246\n",
      "LOSS: 3440268.18575\n",
      "LOSS: 3439748.12735\n",
      "LOSS: 3439360.85896\n",
      "LOSS: 3439079.4149\n",
      "LOSS: 3438867.51325\n",
      "LOSS: 3438698.91683\n",
      "LOSS: 3438553.57105\n",
      "LOSS: 3438422.77553\n",
      "LOSS: 3438308.03775\n",
      "LOSS: 3438212.15337\n",
      "LOSS: 3438135.02439\n",
      "LOSS: 3438073.54715\n",
      "LOSS: 3438023.47774\n",
      "LOSS: 3437980.85168\n",
      "LOSS: 3437943.2764\n",
      "LOSS: 3437909.76317\n",
      "LOSS: 3437880.16844\n",
      "LOSS: 3437854.58562\n",
      "LOSS: 3437833.0309\n",
      "LOSS: 3437815.14733\n",
      "LOSS: 3437800.43061\n",
      "LOSS: 3437788.27557\n",
      "LOSS: 3437778.08327\n",
      "LOSS: 3437769.36423\n",
      "LOSS: 3437761.77158\n",
      "LOSS: 3437755.08644\n",
      "LOSS: 3437749.1844\n",
      "LOSS: 3437743.99802\n",
      "LOSS: 3437739.48738\n",
      "LOSS: 3437735.61237\n",
      "LOSS: 3437732.31974\n",
      "LOSS: 3437729.54283\n",
      "LOSS: 3437727.2067\n",
      "LOSS: 3437725.2343\n",
      "LOSS: 3437723.55489\n",
      "LOSS: 3437722.10748\n",
      "LOSS: 3437720.84624\n",
      "LOSS: 3437719.74112\n",
      "LOSS: 3437718.77442\n",
      "LOSS: 3437717.93594\n",
      "LOSS: 3437717.21816\n",
      "LOSS: 3437716.61267\n",
      "LOSS: 3437716.10828\n",
      "LOSS: 3437715.69107\n",
      "LOSS: 3437715.34552\n",
      "LOSS: 3437715.05639\n",
      "LOSS: 3437714.81026\n",
      "LOSS: 3437714.5967\n",
      "LOSS: 3437714.4085\n",
      "LOSS: 3437714.24136\n",
      "LOSS: 3437714.09303\n",
      "LOSS: 3437713.96239\n",
      "LOSS: 3437713.84867\n",
      "LOSS: 3437713.75083\n",
      "LOSS: 3437713.66742\n",
      "LOSS: 3437713.5966\n",
      "LOSS: 3437713.53635\n",
      "LOSS: 3437713.48474\n",
      "LOSS: 3437713.44014\n",
      "LOSS: 3437713.40134\n",
      "LOSS: 3437713.36752\n",
      "LOSS: 3437713.33817\n",
      "LOSS: 3437713.31295\n",
      "LOSS: 3437713.29157\n",
      "LOSS: 3437713.2737\n",
      "LOSS: 3437713.25891\n",
      "LOSS: 3437713.24671\n",
      "LOSS: 3437713.23658\n",
      "LOSS: 3437713.22801\n",
      "Lamda:  224.1595333 RMSE:  18.3279559881 Val RMSE: 13.6724591907\n",
      "Lamda:  112.07976665\n",
      "LOSS: 2464081.21119\n",
      "LOSS: 2450845.84739\n",
      "LOSS: 2448053.97093\n",
      "LOSS: 2446909.3468\n",
      "LOSS: 2446253.44473\n",
      "LOSS: 2445796.76779\n",
      "LOSS: 2445422.04723\n",
      "LOSS: 2445106.60994\n",
      "LOSS: 2444851.28648\n",
      "LOSS: 2444654.39725\n",
      "LOSS: 2444501.54776\n",
      "LOSS: 2444380.83363\n",
      "LOSS: 2444279.55815\n",
      "LOSS: 2444190.59763\n",
      "LOSS: 2444110.46515\n",
      "LOSS: 2444037.71822\n",
      "LOSS: 2443973.31161\n",
      "LOSS: 2443918.01717\n",
      "LOSS: 2443871.57348\n",
      "LOSS: 2443832.68628\n",
      "LOSS: 2443799.664\n",
      "LOSS: 2443770.91207\n",
      "LOSS: 2443745.31005\n",
      "LOSS: 2443722.2605\n",
      "LOSS: 2443701.55471\n",
      "LOSS: 2443683.17632\n",
      "LOSS: 2443667.11897\n",
      "LOSS: 2443653.30163\n",
      "LOSS: 2443641.54102\n",
      "LOSS: 2443631.56907\n",
      "LOSS: 2443623.08198\n",
      "LOSS: 2443615.78491\n",
      "LOSS: 2443609.42222\n",
      "LOSS: 2443603.79397\n",
      "LOSS: 2443598.74963\n",
      "LOSS: 2443594.18423\n",
      "LOSS: 2443590.02902\n",
      "LOSS: 2443586.24053\n",
      "LOSS: 2443582.79038\n",
      "LOSS: 2443579.65714\n",
      "LOSS: 2443576.8207\n",
      "LOSS: 2443574.25931\n",
      "LOSS: 2443571.94871\n",
      "LOSS: 2443569.86302\n",
      "LOSS: 2443567.97633\n",
      "LOSS: 2443566.26638\n",
      "LOSS: 2443564.71283\n",
      "LOSS: 2443563.30105\n",
      "LOSS: 2443562.02079\n",
      "LOSS: 2443560.86484\n",
      "LOSS: 2443559.82752\n",
      "LOSS: 2443558.90304\n",
      "LOSS: 2443558.08436\n",
      "LOSS: 2443557.36249\n",
      "LOSS: 2443556.72657\n",
      "LOSS: 2443556.16443\n",
      "LOSS: 2443555.6634\n",
      "LOSS: 2443555.21134\n",
      "LOSS: 2443554.79741\n",
      "LOSS: 2443554.41262\n",
      "LOSS: 2443554.05016\n",
      "LOSS: 2443553.70526\n",
      "LOSS: 2443553.37465\n",
      "LOSS: 2443553.05654\n",
      "LOSS: 2443552.75012\n",
      "LOSS: 2443552.45517\n",
      "LOSS: 2443552.17171\n",
      "LOSS: 2443551.89982\n",
      "LOSS: 2443551.63968\n",
      "LOSS: 2443551.39131\n",
      "LOSS: 2443551.15471\n",
      "LOSS: 2443550.92992\n",
      "LOSS: 2443550.71694\n",
      "LOSS: 2443550.5158\n",
      "LOSS: 2443550.32641\n",
      "LOSS: 2443550.14861\n",
      "LOSS: 2443549.98204\n",
      "LOSS: 2443549.82619\n",
      "LOSS: 2443549.68036\n",
      "LOSS: 2443549.54371\n",
      "LOSS: 2443549.41528\n",
      "LOSS: 2443549.29408\n",
      "LOSS: 2443549.17911\n",
      "LOSS: 2443549.06948\n",
      "LOSS: 2443548.96436\n",
      "LOSS: 2443548.86311\n",
      "LOSS: 2443548.76519\n",
      "LOSS: 2443548.67025\n",
      "LOSS: 2443548.57802\n",
      "LOSS: 2443548.48837\n",
      "LOSS: 2443548.40123\n",
      "LOSS: 2443548.31659\n",
      "LOSS: 2443548.23448\n",
      "LOSS: 2443548.15495\n",
      "LOSS: 2443548.07806\n",
      "LOSS: 2443548.00386\n",
      "LOSS: 2443547.93239\n",
      "LOSS: 2443547.86368\n",
      "LOSS: 2443547.79773\n",
      "LOSS: 2443547.73453\n",
      "LOSS: 2443547.67402\n",
      "LOSS: 2443547.61614\n",
      "LOSS: 2443547.5608\n",
      "LOSS: 2443547.50788\n",
      "LOSS: 2443547.45725\n",
      "LOSS: 2443547.40877\n",
      "LOSS: 2443547.3623\n",
      "LOSS: 2443547.31769\n",
      "LOSS: 2443547.27481\n",
      "LOSS: 2443547.23352\n",
      "LOSS: 2443547.19373\n",
      "LOSS: 2443547.15532\n",
      "LOSS: 2443547.11822\n",
      "LOSS: 2443547.08236\n",
      "LOSS: 2443547.0477\n",
      "LOSS: 2443547.01417\n",
      "LOSS: 2443546.98177\n",
      "LOSS: 2443546.95044\n",
      "LOSS: 2443546.92019\n",
      "LOSS: 2443546.89099\n",
      "LOSS: 2443546.86282\n",
      "LOSS: 2443546.83567\n",
      "LOSS: 2443546.80952\n",
      "LOSS: 2443546.78434\n",
      "LOSS: 2443546.76012\n",
      "LOSS: 2443546.73683\n",
      "LOSS: 2443546.71444\n",
      "LOSS: 2443546.69292\n",
      "LOSS: 2443546.67224\n",
      "LOSS: 2443546.65236\n",
      "LOSS: 2443546.63324\n",
      "LOSS: 2443546.61486\n",
      "LOSS: 2443546.59717\n",
      "LOSS: 2443546.58014\n",
      "LOSS: 2443546.56374\n",
      "LOSS: 2443546.54795\n",
      "LOSS: 2443546.53273\n",
      "LOSS: 2443546.51805\n",
      "LOSS: 2443546.5039\n",
      "LOSS: 2443546.49026\n",
      "LOSS: 2443546.4771\n",
      "LOSS: 2443546.46441\n",
      "LOSS: 2443546.45217\n",
      "LOSS: 2443546.44038\n",
      "LOSS: 2443546.42901\n",
      "LOSS: 2443546.41806\n",
      "LOSS: 2443546.4075\n",
      "LOSS: 2443546.39734\n",
      "LOSS: 2443546.38755\n",
      "Lamda:  112.07976665 RMSE:  18.3279559881 Val RMSE: 12.0830292975\n",
      "Lamda:  56.039883325\n",
      "LOSS: 1768040.19352\n",
      "LOSS: 1758448.94576\n",
      "LOSS: 1756473.6139\n",
      "LOSS: 1755676.67988\n",
      "LOSS: 1755227.14291\n",
      "LOSS: 1754930.06243\n",
      "LOSS: 1754708.69063\n",
      "LOSS: 1754529.70575\n",
      "LOSS: 1754379.74028\n",
      "LOSS: 1754256.68366\n",
      "LOSS: 1754158.57492\n",
      "LOSS: 1754082.03964\n",
      "LOSS: 1754022.10437\n",
      "LOSS: 1753973.28077\n",
      "LOSS: 1753931.14532\n",
      "LOSS: 1753893.24296\n",
      "LOSS: 1753858.43725\n",
      "LOSS: 1753826.68603\n",
      "LOSS: 1753798.35509\n",
      "LOSS: 1753773.68858\n",
      "LOSS: 1753752.59123\n",
      "LOSS: 1753734.67559\n",
      "LOSS: 1753719.37427\n",
      "LOSS: 1753706.09692\n",
      "LOSS: 1753694.32662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 1753683.61819\n",
      "LOSS: 1753673.73521\n",
      "LOSS: 1753664.57042\n",
      "LOSS: 1753656.09003\n",
      "LOSS: 1753648.28712\n",
      "LOSS: 1753641.1573\n",
      "LOSS: 1753634.68279\n",
      "LOSS: 1753628.82971\n",
      "LOSS: 1753623.55122\n",
      "LOSS: 1753618.79398\n",
      "LOSS: 1753614.50377\n",
      "LOSS: 1753610.62908\n",
      "LOSS: 1753607.12478\n",
      "LOSS: 1753603.94822\n",
      "LOSS: 1753601.06476\n",
      "LOSS: 1753598.44828\n",
      "LOSS: 1753596.07662\n",
      "LOSS: 1753593.93011\n",
      "LOSS: 1753592.1488\n",
      "LOSS: 1753590.56572\n",
      "LOSS: 1753589.15723\n",
      "LOSS: 1753587.90831\n",
      "LOSS: 1753586.80384\n",
      "LOSS: 1753585.82831\n",
      "LOSS: 1753584.96583\n",
      "LOSS: 1753584.2004\n",
      "LOSS: 1753583.51627\n",
      "LOSS: 1753582.90168\n",
      "LOSS: 1753582.3412\n",
      "LOSS: 1753581.82293\n",
      "LOSS: 1753581.33844\n",
      "LOSS: 1753580.8818\n",
      "LOSS: 1753580.44919\n",
      "LOSS: 1753580.03855\n",
      "LOSS: 1753579.64901\n",
      "LOSS: 1753579.32887\n",
      "LOSS: 1753579.10968\n",
      "LOSS: 1753578.9235\n",
      "LOSS: 1753578.75951\n",
      "LOSS: 1753578.61499\n",
      "LOSS: 1753578.48764\n",
      "LOSS: 1753578.37485\n",
      "LOSS: 1753578.27413\n",
      "LOSS: 1753578.18337\n",
      "LOSS: 1753578.10101\n",
      "LOSS: 1753578.0259\n",
      "LOSS: 1753577.95733\n",
      "LOSS: 1753577.89482\n",
      "LOSS: 1753577.83803\n",
      "LOSS: 1753577.78668\n",
      "LOSS: 1753577.7405\n",
      "LOSS: 1753577.69922\n",
      "LOSS: 1753577.6626\n",
      "LOSS: 1753577.6303\n",
      "LOSS: 1753577.60183\n",
      "LOSS: 1753577.57669\n",
      "LOSS: 1753577.55441\n",
      "LOSS: 1753577.53457\n",
      "LOSS: 1753577.5168\n",
      "LOSS: 1753577.50078\n",
      "LOSS: 1753577.48631\n",
      "LOSS: 1753577.47323\n",
      "LOSS: 1753577.46143\n",
      "LOSS: 1753577.45083\n",
      "LOSS: 1753577.44138\n",
      "Lamda:  56.039883325 RMSE:  18.3279559881 Val RMSE: 10.8758990385\n",
      "Lamda:  28.0199416625\n",
      "LOSS: 1286416.53105\n",
      "LOSS: 1279772.71321\n",
      "LOSS: 1278242.63832\n",
      "LOSS: 1277608.27065\n",
      "LOSS: 1277264.1089\n",
      "LOSS: 1277043.24172\n",
      "LOSS: 1276889.50649\n",
      "LOSS: 1276775.5191\n",
      "LOSS: 1276685.42341\n",
      "LOSS: 1276615.58251\n",
      "LOSS: 1276559.40411\n",
      "LOSS: 1276514.30832\n",
      "LOSS: 1276478.35341\n",
      "LOSS: 1276449.5532\n",
      "LOSS: 1276425.94886\n",
      "LOSS: 1276405.78483\n",
      "LOSS: 1276387.83297\n",
      "LOSS: 1276371.42453\n",
      "LOSS: 1276356.28251\n",
      "LOSS: 1276342.35667\n",
      "LOSS: 1276329.71531\n",
      "LOSS: 1276318.44129\n",
      "LOSS: 1276308.649\n",
      "LOSS: 1276300.21736\n",
      "LOSS: 1276293.00154\n",
      "LOSS: 1276286.84156\n",
      "LOSS: 1276281.49136\n",
      "LOSS: 1276276.73001\n",
      "LOSS: 1276272.42428\n",
      "LOSS: 1276268.47955\n",
      "LOSS: 1276264.84219\n",
      "LOSS: 1276261.47865\n",
      "LOSS: 1276258.37415\n",
      "LOSS: 1276255.52357\n",
      "LOSS: 1276252.92431\n",
      "LOSS: 1276250.57203\n",
      "LOSS: 1276248.45785\n",
      "LOSS: 1276246.56917\n",
      "LOSS: 1276244.89033\n",
      "LOSS: 1276243.40304\n",
      "LOSS: 1276242.08727\n",
      "LOSS: 1276240.92226\n",
      "LOSS: 1276239.88715\n",
      "LOSS: 1276238.96203\n",
      "LOSS: 1276238.12909\n",
      "LOSS: 1276237.37315\n",
      "LOSS: 1276236.68228\n",
      "LOSS: 1276236.04696\n",
      "LOSS: 1276235.4608\n",
      "LOSS: 1276234.91957\n",
      "LOSS: 1276234.42073\n",
      "LOSS: 1276233.96274\n",
      "LOSS: 1276233.54448\n",
      "LOSS: 1276233.1648\n",
      "LOSS: 1276232.82258\n",
      "LOSS: 1276232.51525\n",
      "LOSS: 1276232.24029\n",
      "LOSS: 1276231.99453\n",
      "LOSS: 1276231.77474\n",
      "LOSS: 1276231.5777\n",
      "LOSS: 1276231.40039\n",
      "LOSS: 1276231.24002\n",
      "LOSS: 1276231.09447\n",
      "LOSS: 1276230.96184\n",
      "LOSS: 1276230.84063\n",
      "LOSS: 1276230.7298\n",
      "LOSS: 1276230.62863\n",
      "LOSS: 1276230.53663\n",
      "LOSS: 1276230.45341\n",
      "LOSS: 1276230.37858\n",
      "LOSS: 1276230.31169\n",
      "LOSS: 1276230.25221\n",
      "LOSS: 1276230.1995\n",
      "LOSS: 1276230.15284\n",
      "LOSS: 1276230.11144\n",
      "LOSS: 1276230.07454\n",
      "LOSS: 1276230.0414\n",
      "LOSS: 1276230.01132\n",
      "LOSS: 1276229.98373\n",
      "LOSS: 1276229.95817\n",
      "LOSS: 1276229.9343\n",
      "LOSS: 1276229.91189\n",
      "LOSS: 1276229.89081\n",
      "LOSS: 1276229.87103\n",
      "LOSS: 1276229.85251\n",
      "LOSS: 1276229.83526\n",
      "LOSS: 1276229.81929\n",
      "LOSS: 1276229.80458\n",
      "LOSS: 1276229.7911\n",
      "LOSS: 1276229.77881\n",
      "LOSS: 1276229.76762\n",
      "LOSS: 1276229.75747\n",
      "LOSS: 1276229.74825\n",
      "Lamda:  28.0199416625 RMSE:  18.3279559881 Val RMSE: 10.0951980186\n",
      "Lamda:  14.0099708312\n",
      "LOSS: 963998.697368\n",
      "LOSS: 959253.174229\n",
      "LOSS: 958005.680816\n",
      "LOSS: 957502.747744\n",
      "LOSS: 957246.929661\n",
      "LOSS: 957097.409294\n",
      "LOSS: 956999.820755\n",
      "LOSS: 956930.887403\n",
      "LOSS: 956879.061523\n",
      "LOSS: 956838.017218\n",
      "LOSS: 956804.03959\n",
      "LOSS: 956774.796573\n",
      "LOSS: 956748.956942\n",
      "LOSS: 956726.055822\n",
      "LOSS: 956706.192318\n",
      "LOSS: 956688.377782\n",
      "LOSS: 956672.394729\n",
      "LOSS: 956658.256484\n",
      "LOSS: 956645.786653\n",
      "LOSS: 956634.873257\n",
      "LOSS: 956625.690046\n",
      "LOSS: 956618.751476\n",
      "LOSS: 956612.980564\n",
      "LOSS: 956608.001838\n",
      "LOSS: 956603.608001\n",
      "LOSS: 956599.659163\n",
      "LOSS: 956596.112458\n",
      "LOSS: 956592.934839\n",
      "LOSS: 956590.128187\n",
      "LOSS: 956587.688084\n",
      "LOSS: 956585.485679\n",
      "LOSS: 956583.489119\n",
      "LOSS: 956581.671261\n",
      "LOSS: 956580.011066\n",
      "LOSS: 956578.493064\n",
      "LOSS: 956577.105267\n",
      "LOSS: 956575.838418\n",
      "LOSS: 956574.684652\n",
      "LOSS: 956573.63822\n",
      "LOSS: 956572.69305\n",
      "LOSS: 956571.842846\n",
      "LOSS: 956571.080121\n",
      "LOSS: 956570.396895\n",
      "LOSS: 956569.784762\n",
      "LOSS: 956569.235125\n",
      "LOSS: 956568.739901\n",
      "LOSS: 956568.291405\n",
      "LOSS: 956567.883234\n",
      "LOSS: 956567.509445\n",
      "LOSS: 956567.165159\n",
      "LOSS: 956566.846494\n",
      "LOSS: 956566.550473\n",
      "LOSS: 956566.2749\n",
      "LOSS: 956566.01821\n",
      "LOSS: 956565.779306\n",
      "LOSS: 956565.557404\n",
      "LOSS: 956565.351894\n",
      "LOSS: 956565.162245\n",
      "LOSS: 956564.987894\n",
      "LOSS: 956564.82816\n",
      "LOSS: 956564.682303\n",
      "LOSS: 956564.549407\n",
      "LOSS: 956564.428486\n",
      "LOSS: 956564.318525\n",
      "LOSS: 956564.218504\n",
      "LOSS: 956564.127433\n",
      "LOSS: 956564.044382\n",
      "LOSS: 956563.96851\n",
      "LOSS: 956563.899075\n",
      "LOSS: 956563.835447\n",
      "LOSS: 956563.777097\n",
      "LOSS: 956563.723593\n",
      "LOSS: 956563.674579\n",
      "LOSS: 956563.629756\n",
      "LOSS: 956563.588861\n",
      "LOSS: 956563.55165\n",
      "LOSS: 956563.5179\n",
      "LOSS: 956563.487379\n",
      "LOSS: 956563.459845\n",
      "LOSS: 956563.435039\n",
      "LOSS: 956563.412698\n",
      "LOSS: 956563.392553\n",
      "LOSS: 956563.374338\n",
      "LOSS: 956563.357799\n",
      "LOSS: 956563.3427\n",
      "LOSS: 956563.328827\n",
      "LOSS: 956563.315997\n",
      "LOSS: 956563.304057\n",
      "LOSS: 956563.292882\n",
      "LOSS: 956563.282379\n",
      "LOSS: 956563.272475\n",
      "Lamda:  14.0099708312 RMSE:  18.3279559881 Val RMSE: 9.70771962207\n",
      "Lamda:  7.00498541562\n",
      "LOSS: 758183.63879\n",
      "LOSS: 755307.569421\n",
      "LOSS: 754443.006803\n",
      "LOSS: 754082.4543\n",
      "LOSS: 753898.092838\n",
      "LOSS: 753791.908757\n",
      "LOSS: 753726.987767\n",
      "LOSS: 753684.946695\n",
      "LOSS: 753657.177453\n",
      "LOSS: 753637.993873\n",
      "LOSS: 753623.904728\n",
      "LOSS: 753612.912216\n",
      "LOSS: 753604.590311\n",
      "LOSS: 753597.684215\n",
      "LOSS: 753591.647808\n",
      "LOSS: 753586.259248\n",
      "LOSS: 753581.404136\n",
      "LOSS: 753577.015964\n",
      "LOSS: 753573.051728\n",
      "LOSS: 753569.479362\n",
      "LOSS: 753566.271425\n",
      "LOSS: 753563.402236\n",
      "LOSS: 753560.846658\n",
      "LOSS: 753558.578248\n",
      "LOSS: 753556.573964\n",
      "LOSS: 753554.832054\n",
      "LOSS: 753553.299559\n",
      "LOSS: 753551.954023\n",
      "LOSS: 753550.767873\n",
      "LOSS: 753549.714608\n",
      "LOSS: 753548.770669\n",
      "LOSS: 753547.91369\n",
      "LOSS: 753547.125857\n",
      "LOSS: 753546.392841\n",
      "LOSS: 753545.70414\n",
      "LOSS: 753545.052315\n",
      "LOSS: 753544.433239\n",
      "LOSS: 753543.845823\n",
      "LOSS: 753543.290322\n",
      "LOSS: 753542.768086\n",
      "LOSS: 753542.280915\n",
      "LOSS: 753541.830538\n",
      "LOSS: 753541.418169\n",
      "LOSS: 753541.044319\n",
      "LOSS: 753540.708656\n",
      "LOSS: 753540.40997\n",
      "LOSS: 753540.146359\n",
      "LOSS: 753539.915282\n",
      "LOSS: 753539.713179\n",
      "LOSS: 753539.536567\n",
      "LOSS: 753539.381956\n",
      "LOSS: 753539.245964\n",
      "LOSS: 753539.12653\n",
      "LOSS: 753539.021365\n",
      "LOSS: 753538.926578\n",
      "LOSS: 753538.840271\n",
      "LOSS: 753538.761069\n",
      "LOSS: 753538.687812\n",
      "LOSS: 753538.619716\n",
      "LOSS: 753538.556291\n",
      "LOSS: 753538.497251\n",
      "LOSS: 753538.442442\n",
      "LOSS: 753538.391777\n",
      "LOSS: 753538.345196\n",
      "LOSS: 753538.30261\n",
      "LOSS: 753538.263855\n",
      "LOSS: 753538.228783\n",
      "LOSS: 753538.197172\n",
      "LOSS: 753538.168735\n",
      "LOSS: 753538.143132\n",
      "LOSS: 753538.119996\n",
      "LOSS: 753538.098952\n",
      "LOSS: 753538.079639\n",
      "LOSS: 753538.061726\n",
      "LOSS: 753538.044925\n",
      "LOSS: 753538.029001\n",
      "LOSS: 753538.013777\n",
      "LOSS: 753537.999125\n",
      "LOSS: 753537.98497\n",
      "LOSS: 753537.97128\n",
      "LOSS: 753537.958056\n",
      "LOSS: 753537.945322\n",
      "LOSS: 753537.933115\n",
      "LOSS: 753537.921475\n",
      "LOSS: 753537.910437\n",
      "LOSS: 753537.900029\n",
      "LOSS: 753537.890262\n",
      "Lamda:  7.00498541562 RMSE:  18.3279559881 Val RMSE: 9.65549792506\n",
      "Lamda:  3.50249270781\n",
      "LOSS: 635585.442191\n",
      "LOSS: 634295.24938\n",
      "LOSS: 633854.625307\n",
      "LOSS: 633652.467342\n",
      "LOSS: 633543.233304\n",
      "LOSS: 633477.370388\n",
      "LOSS: 633434.979424\n",
      "LOSS: 633406.417351\n",
      "LOSS: 633386.310117\n",
      "LOSS: 633371.658394\n",
      "LOSS: 633360.637944\n",
      "LOSS: 633352.299329\n",
      "LOSS: 633345.604536\n",
      "LOSS: 633340.064728\n",
      "LOSS: 633335.486752\n",
      "LOSS: 633331.547798\n",
      "LOSS: 633328.067424\n",
      "LOSS: 633324.949201\n",
      "LOSS: 633322.129194\n",
      "LOSS: 633319.56415\n",
      "LOSS: 633317.317925\n",
      "LOSS: 633315.34969\n",
      "LOSS: 633313.564731\n",
      "LOSS: 633311.950438\n",
      "LOSS: 633310.493249\n",
      "LOSS: 633309.182623\n",
      "LOSS: 633308.014599\n",
      "LOSS: 633306.97464\n",
      "LOSS: 633306.046031\n",
      "LOSS: 633305.216274\n",
      "LOSS: 633304.474724\n",
      "LOSS: 633303.812247\n",
      "LOSS: 633303.217245\n",
      "LOSS: 633302.68047\n",
      "LOSS: 633302.193686\n",
      "LOSS: 633301.74958\n",
      "LOSS: 633301.341872\n",
      "LOSS: 633300.965316\n",
      "LOSS: 633300.615692\n",
      "LOSS: 633300.289718\n",
      "LOSS: 633299.984897\n",
      "LOSS: 633299.699415\n",
      "LOSS: 633299.432006\n",
      "LOSS: 633299.18181\n",
      "LOSS: 633298.948238\n",
      "LOSS: 633298.730863\n",
      "LOSS: 633298.529319\n",
      "LOSS: 633298.343217\n",
      "LOSS: 633298.172099\n",
      "LOSS: 633298.015396\n",
      "LOSS: 633297.872422\n",
      "LOSS: 633297.742371\n",
      "LOSS: 633297.62434\n",
      "LOSS: 633297.517349\n",
      "LOSS: 633297.420366\n",
      "LOSS: 633297.332347\n",
      "LOSS: 633297.252296\n",
      "LOSS: 633297.179246\n",
      "LOSS: 633297.112298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 633297.050645\n",
      "LOSS: 633296.99358\n",
      "LOSS: 633296.940503\n",
      "LOSS: 633296.890919\n",
      "LOSS: 633296.84443\n",
      "LOSS: 633296.800728\n",
      "LOSS: 633296.759577\n",
      "LOSS: 633296.720805\n",
      "LOSS: 633296.684285\n",
      "LOSS: 633296.649922\n",
      "LOSS: 633296.617639\n",
      "LOSS: 633296.587372\n",
      "LOSS: 633296.559055\n",
      "LOSS: 633296.532618\n",
      "LOSS: 633296.507979\n",
      "LOSS: 633296.485046\n",
      "LOSS: 633296.463714\n",
      "LOSS: 633296.443872\n",
      "LOSS: 633296.425397\n",
      "LOSS: 633296.408166\n",
      "LOSS: 633296.392055\n",
      "LOSS: 633296.376941\n",
      "LOSS: 633296.362711\n",
      "LOSS: 633296.349258\n",
      "LOSS: 633296.336488\n",
      "LOSS: 633296.324318\n",
      "LOSS: 633296.312679\n",
      "LOSS: 633296.301512\n",
      "LOSS: 633296.290773\n",
      "LOSS: 633296.280427\n",
      "LOSS: 633296.270447\n",
      "Lamda:  3.50249270781 RMSE:  18.3279559881 Val RMSE: 9.73439927875\n",
      "Lamda:  7.00498541562\n",
      "LOSS: 756197.335309\n",
      "LOSS: 754648.161082\n",
      "LOSS: 754112.720208\n",
      "LOSS: 753877.285726\n",
      "LOSS: 753758.831752\n",
      "LOSS: 753697.524356\n",
      "LOSS: 753659.195276\n",
      "LOSS: 753633.940841\n",
      "LOSS: 753616.287284\n",
      "LOSS: 753603.006069\n",
      "LOSS: 753592.549613\n",
      "LOSS: 753584.099569\n",
      "LOSS: 753576.984551\n",
      "LOSS: 753570.910022\n",
      "LOSS: 753565.82234\n",
      "LOSS: 753562.797222\n",
      "LOSS: 753560.117833\n",
      "LOSS: 753557.727523\n",
      "LOSS: 753555.616608\n",
      "LOSS: 753553.738132\n",
      "LOSS: 753552.064106\n",
      "LOSS: 753550.577794\n",
      "LOSS: 753549.263271\n",
      "LOSS: 753548.105047\n",
      "LOSS: 753547.092974\n",
      "LOSS: 753546.208128\n",
      "LOSS: 753545.431796\n",
      "LOSS: 753544.748304\n",
      "LOSS: 753544.143296\n",
      "LOSS: 753543.603732\n",
      "LOSS: 753543.11794\n",
      "LOSS: 753542.675872\n",
      "LOSS: 753542.269404\n",
      "LOSS: 753541.892144\n",
      "LOSS: 753541.539552\n",
      "LOSS: 753541.20896\n",
      "LOSS: 753540.898283\n",
      "LOSS: 753540.606292\n",
      "LOSS: 753540.332733\n",
      "LOSS: 753540.077774\n",
      "LOSS: 753539.841718\n",
      "LOSS: 753539.624822\n",
      "LOSS: 753539.427114\n",
      "LOSS: 753539.248314\n",
      "LOSS: 753539.087736\n",
      "LOSS: 753538.944432\n",
      "LOSS: 753538.817234\n",
      "LOSS: 753538.704744\n",
      "LOSS: 753538.605457\n",
      "LOSS: 753538.517664\n",
      "LOSS: 753538.439762\n",
      "LOSS: 753538.370237\n",
      "LOSS: 753538.307711\n",
      "LOSS: 753538.25101\n",
      "LOSS: 753538.199182\n",
      "LOSS: 753538.151485\n",
      "LOSS: 753538.107374\n",
      "LOSS: 753538.06648\n",
      "LOSS: 753538.028578\n",
      "LOSS: 753537.993523\n",
      "LOSS: 753537.961247\n",
      "LOSS: 753537.93171\n",
      "LOSS: 753537.90488\n",
      "LOSS: 753537.880703\n",
      "LOSS: 753537.859096\n",
      "LOSS: 753537.839935\n",
      "LOSS: 753537.823103\n",
      "LOSS: 753537.808363\n",
      "LOSS: 753537.795476\n",
      "LOSS: 753537.784202\n",
      "LOSS: 753537.7743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.0049854156249758"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.chooseCorrectLamda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEEI4OQkCIYRwchIEQgjh5CQIhBDCyf1/VWmTPYyM0coAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f23d2a750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(model.trainlamda, model.trainrmse)\n",
    "plt.plot(model.vallamda, model.valrmse)\n",
    "plt.ylabel('RMSE')\n",
    "plt.xlabel('Lamda')\n",
    "ax = plt.gca()\n",
    "ax.invert_xaxis()\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n",
    "#plt.savefig('RMSEvsLamda.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJLgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f23d2a450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(model.NonZero)\n",
    "plt.ylabel('Non Zero')\n",
    "plt.xlabel('Iterations')\n",
    "#plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n",
    "#plt.savefig('NonZeroElements.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.saveModel('savedModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.65528920327\n",
      "8.92292105178\n",
      "[ 105.71206656   85.54415933   87.60385796 ...,   87.82942353   87.01643808\n",
      "   85.78716094]\n",
      "[92 90 86 ..., 92 89 88]\n"
     ]
    }
   ],
   "source": [
    "print rmse(model.predict(valX), valY)\n",
    "print rmse(X.transpose() * model.W, valY)\n",
    "print model.predict(valX)\n",
    "print valY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 105.71206656   85.54415933   87.60385796 ...,   87.82942353   87.01643808\n",
      "   85.78716094]\n"
     ]
    }
   ],
   "source": [
    "testXDF = pd.read_csv('Data/testData.txt', names = ['instanceID', 'featureID', 'value'], sep=' ')\n",
    "testX = csr_matrix((valXDF['value'], (valXDF['featureID'], valXDF['instanceID'])))\n",
    "testPredicted = model.predict(testX)\n",
    "print testPredicted\n",
    "np.savetxt(\"out.csv\", testPredicted, delimiter=\",\")\n",
    "#testPredicted.to_csv('out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
